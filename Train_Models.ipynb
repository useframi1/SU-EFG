{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T23:18:02.668553Z",
     "start_time": "2024-04-01T23:18:02.660261Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4245291402f6d5a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T21:53:46.636764Z",
     "start_time": "2024-04-01T21:52:42.575659Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cleaned_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc876988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13523 entries, 0 to 13522\n",
      "Columns: 509 entries, ClientID to Churned\n",
      "dtypes: float64(373), int64(136)\n",
      "memory usage: 52.5 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f69a85fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(columns=['Churned'])\n",
    "label = df[\"Churned\"]\n",
    "X_Train , X_Test , y_train , y_test = train_test_split(features, label, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b979431b54d59a60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T21:54:53.650202Z",
     "start_time": "2024-04-01T21:54:53.564751Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "KF = KFold(n_splits=5)\n",
    "def Model_Train(Model, X, Y):\n",
    "    Preds = []\n",
    "    for i,j in KF.split(X):\n",
    "        Train_X = X.iloc[i]\n",
    "        Test_X = X.iloc[j]\n",
    "        Train_Y = Y.iloc[i]\n",
    "        \n",
    "        Model.fit(Train_X, Train_Y)\n",
    "        Pred_Y = Model.predict(Test_X)\n",
    "        Preds.append(Pred_Y)\n",
    "    print(classification_report(Y, np.concatenate(Preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e96e70c58588c56",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Classification:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecf83ec7649e441",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "940f63930bba8265",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T13:21:33.716386Z",
     "start_time": "2024-04-01T10:38:41.001965Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 52 candidates, totalling 260 fits\n",
      "[CV 1/5] END .....................n_neighbors=1;, score=0.716 total time=   0.4s\n",
      "[CV 2/5] END .....................n_neighbors=1;, score=0.709 total time=   0.2s\n",
      "[CV 3/5] END .....................n_neighbors=1;, score=0.704 total time=   0.2s\n",
      "[CV 4/5] END .....................n_neighbors=1;, score=0.706 total time=   0.2s\n",
      "[CV 5/5] END .....................n_neighbors=1;, score=0.738 total time=   0.2s\n",
      "[CV 1/5] END .....................n_neighbors=3;, score=0.730 total time=   0.2s\n",
      "[CV 2/5] END .....................n_neighbors=3;, score=0.719 total time=   0.2s\n",
      "[CV 3/5] END .....................n_neighbors=3;, score=0.720 total time=   0.2s\n",
      "[CV 4/5] END .....................n_neighbors=3;, score=0.708 total time=   0.2s\n",
      "[CV 5/5] END .....................n_neighbors=3;, score=0.728 total time=   0.2s\n",
      "[CV 1/5] END .....................n_neighbors=5;, score=0.724 total time=   0.2s\n",
      "[CV 2/5] END .....................n_neighbors=5;, score=0.729 total time=   0.2s\n",
      "[CV 3/5] END .....................n_neighbors=5;, score=0.709 total time=   0.2s\n",
      "[CV 4/5] END .....................n_neighbors=5;, score=0.716 total time=   0.2s\n",
      "[CV 5/5] END .....................n_neighbors=5;, score=0.726 total time=   0.2s\n",
      "[CV 1/5] END .....................n_neighbors=7;, score=0.727 total time=   0.2s\n",
      "[CV 2/5] END .....................n_neighbors=7;, score=0.744 total time=   0.2s\n",
      "[CV 3/5] END .....................n_neighbors=7;, score=0.714 total time=   0.2s\n",
      "[CV 4/5] END .....................n_neighbors=7;, score=0.713 total time=   0.2s\n",
      "[CV 5/5] END .....................n_neighbors=7;, score=0.726 total time=   0.2s\n",
      "[CV 1/5] END .....................n_neighbors=9;, score=0.726 total time=   0.2s\n",
      "[CV 2/5] END .....................n_neighbors=9;, score=0.747 total time=   0.2s\n",
      "[CV 3/5] END .....................n_neighbors=9;, score=0.718 total time=   0.2s\n",
      "[CV 4/5] END .....................n_neighbors=9;, score=0.709 total time=   0.2s\n",
      "[CV 5/5] END .....................n_neighbors=9;, score=0.734 total time=   0.2s\n",
      "[CV 1/5] END ....................n_neighbors=11;, score=0.728 total time=   0.2s\n",
      "[CV 2/5] END ....................n_neighbors=11;, score=0.738 total time=   0.2s\n",
      "[CV 3/5] END ....................n_neighbors=11;, score=0.721 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=11;, score=0.717 total time=   0.2s\n",
      "[CV 5/5] END ....................n_neighbors=11;, score=0.744 total time=   0.2s\n",
      "[CV 1/5] END ....................n_neighbors=13;, score=0.732 total time=   0.2s\n",
      "[CV 2/5] END ....................n_neighbors=13;, score=0.744 total time=   0.2s\n",
      "[CV 3/5] END ....................n_neighbors=13;, score=0.730 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=13;, score=0.721 total time=   0.2s\n",
      "[CV 5/5] END ....................n_neighbors=13;, score=0.739 total time=   0.3s\n",
      "[CV 1/5] END ....................n_neighbors=15;, score=0.732 total time=   0.2s\n",
      "[CV 2/5] END ....................n_neighbors=15;, score=0.748 total time=   0.2s\n",
      "[CV 3/5] END ....................n_neighbors=15;, score=0.737 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=15;, score=0.719 total time=   0.2s\n",
      "[CV 5/5] END ....................n_neighbors=15;, score=0.747 total time=   0.2s\n",
      "[CV 1/5] END ....................n_neighbors=17;, score=0.739 total time=   0.2s\n",
      "[CV 2/5] END ....................n_neighbors=17;, score=0.751 total time=   0.2s\n",
      "[CV 3/5] END ....................n_neighbors=17;, score=0.741 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=17;, score=0.726 total time=   0.2s\n",
      "[CV 5/5] END ....................n_neighbors=17;, score=0.743 total time=   0.2s\n",
      "[CV 1/5] END ....................n_neighbors=19;, score=0.744 total time=   0.2s\n",
      "[CV 2/5] END ....................n_neighbors=19;, score=0.753 total time=   0.2s\n",
      "[CV 3/5] END ....................n_neighbors=19;, score=0.743 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=19;, score=0.734 total time=   0.2s\n",
      "[CV 5/5] END ....................n_neighbors=19;, score=0.742 total time=   0.2s\n",
      "[CV 1/5] END ....................n_neighbors=21;, score=0.739 total time=   0.2s\n",
      "[CV 2/5] END ....................n_neighbors=21;, score=0.756 total time=   0.2s\n",
      "[CV 3/5] END ....................n_neighbors=21;, score=0.738 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=21;, score=0.737 total time=   0.2s\n",
      "[CV 5/5] END ....................n_neighbors=21;, score=0.750 total time=   0.2s\n",
      "[CV 1/5] END ....................n_neighbors=23;, score=0.744 total time=   0.2s\n",
      "[CV 2/5] END ....................n_neighbors=23;, score=0.751 total time=   0.2s\n",
      "[CV 3/5] END ....................n_neighbors=23;, score=0.739 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=23;, score=0.740 total time=   0.2s\n",
      "[CV 5/5] END ....................n_neighbors=23;, score=0.748 total time=   0.2s\n",
      "[CV 1/5] END ....................n_neighbors=25;, score=0.748 total time=   0.2s\n",
      "[CV 2/5] END ....................n_neighbors=25;, score=0.745 total time=   0.2s\n",
      "[CV 3/5] END ....................n_neighbors=25;, score=0.745 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=25;, score=0.740 total time=   0.2s\n",
      "[CV 5/5] END ....................n_neighbors=25;, score=0.755 total time=   0.2s\n",
      "[CV 1/5] END ....................n_neighbors=27;, score=0.748 total time=   0.2s\n",
      "[CV 2/5] END ....................n_neighbors=27;, score=0.746 total time=   0.2s\n",
      "[CV 3/5] END ....................n_neighbors=27;, score=0.744 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=27;, score=0.740 total time=   0.2s\n",
      "[CV 5/5] END ....................n_neighbors=27;, score=0.754 total time=   0.2s\n",
      "[CV 1/5] END ....................n_neighbors=29;, score=0.754 total time=   0.2s\n",
      "[CV 2/5] END ....................n_neighbors=29;, score=0.749 total time=   0.2s\n",
      "[CV 3/5] END ....................n_neighbors=29;, score=0.748 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=29;, score=0.743 total time=   0.2s\n",
      "[CV 5/5] END ....................n_neighbors=29;, score=0.755 total time=   0.2s\n",
      "[CV 1/5] END ....................n_neighbors=31;, score=0.752 total time=   0.2s\n",
      "[CV 2/5] END ....................n_neighbors=31;, score=0.747 total time=   0.2s\n",
      "[CV 3/5] END ....................n_neighbors=31;, score=0.745 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=31;, score=0.747 total time=   0.2s\n",
      "[CV 5/5] END ....................n_neighbors=31;, score=0.750 total time=   0.2s\n",
      "[CV 1/5] END ....................n_neighbors=33;, score=0.751 total time=   0.2s\n",
      "[CV 2/5] END ....................n_neighbors=33;, score=0.750 total time=   0.2s\n",
      "[CV 3/5] END ....................n_neighbors=33;, score=0.748 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=33;, score=0.745 total time=   0.2s\n",
      "[CV 5/5] END ....................n_neighbors=33;, score=0.752 total time=   0.2s\n",
      "[CV 1/5] END ....................n_neighbors=35;, score=0.752 total time=   0.2s\n",
      "[CV 2/5] END ....................n_neighbors=35;, score=0.755 total time=   0.2s\n",
      "[CV 3/5] END ....................n_neighbors=35;, score=0.744 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=35;, score=0.746 total time=   0.2s\n",
      "[CV 5/5] END ....................n_neighbors=35;, score=0.757 total time=   0.2s\n",
      "[CV 1/5] END ....................n_neighbors=37;, score=0.749 total time=   0.2s\n",
      "[CV 2/5] END ....................n_neighbors=37;, score=0.751 total time=   0.2s\n",
      "[CV 3/5] END ....................n_neighbors=37;, score=0.747 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=37;, score=0.745 total time=   0.2s\n",
      "[CV 5/5] END ....................n_neighbors=37;, score=0.754 total time=   0.2s\n",
      "[CV 1/5] END ....................n_neighbors=39;, score=0.746 total time=   0.2s\n",
      "[CV 2/5] END ....................n_neighbors=39;, score=0.748 total time=   0.2s\n",
      "[CV 3/5] END ....................n_neighbors=39;, score=0.746 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=39;, score=0.748 total time=   0.2s\n",
      "[CV 5/5] END ....................n_neighbors=39;, score=0.755 total time=   0.2s\n",
      "[CV 1/5] END ....................n_neighbors=41;, score=0.749 total time=   0.2s\n",
      "[CV 2/5] END ....................n_neighbors=41;, score=0.750 total time=   0.2s\n",
      "[CV 3/5] END ....................n_neighbors=41;, score=0.749 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=41;, score=0.749 total time=   0.2s\n",
      "[CV 5/5] END ....................n_neighbors=41;, score=0.753 total time=   0.2s\n",
      "[CV 1/5] END ....................n_neighbors=43;, score=0.752 total time=   0.2s\n",
      "[CV 2/5] END ....................n_neighbors=43;, score=0.754 total time=   0.2s\n",
      "[CV 3/5] END ....................n_neighbors=43;, score=0.750 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=43;, score=0.752 total time=   0.2s\n",
      "[CV 5/5] END ....................n_neighbors=43;, score=0.750 total time=   0.2s\n",
      "[CV 1/5] END ....................n_neighbors=45;, score=0.754 total time=   0.2s\n",
      "[CV 2/5] END ....................n_neighbors=45;, score=0.753 total time=   0.2s\n",
      "[CV 3/5] END ....................n_neighbors=45;, score=0.752 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=45;, score=0.752 total time=   0.2s\n",
      "[CV 5/5] END ....................n_neighbors=45;, score=0.751 total time=   0.2s\n",
      "[CV 1/5] END ....................n_neighbors=47;, score=0.753 total time=   0.2s\n",
      "[CV 2/5] END ....................n_neighbors=47;, score=0.751 total time=   0.2s\n",
      "[CV 3/5] END ....................n_neighbors=47;, score=0.756 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=47;, score=0.754 total time=   0.2s\n",
      "[CV 5/5] END ....................n_neighbors=47;, score=0.753 total time=   0.2s\n",
      "[CV 1/5] END ....................n_neighbors=49;, score=0.745 total time=   0.2s\n",
      "[CV 2/5] END ....................n_neighbors=49;, score=0.751 total time=   0.2s\n",
      "[CV 3/5] END ....................n_neighbors=49;, score=0.754 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=49;, score=0.753 total time=   0.2s\n",
      "[CV 5/5] END ....................n_neighbors=49;, score=0.750 total time=   0.2s\n",
      "[CV 1/5] END ....................n_neighbors=51;, score=0.745 total time=   0.2s\n",
      "[CV 2/5] END ....................n_neighbors=51;, score=0.754 total time=   0.2s\n",
      "[CV 3/5] END ....................n_neighbors=51;, score=0.753 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=51;, score=0.751 total time=   0.2s\n",
      "[CV 5/5] END ....................n_neighbors=51;, score=0.748 total time=   0.2s\n",
      "[CV 1/5] END ....................n_neighbors=53;, score=0.746 total time=   0.2s\n",
      "[CV 2/5] END ....................n_neighbors=53;, score=0.753 total time=   0.2s\n",
      "[CV 3/5] END ....................n_neighbors=53;, score=0.756 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=53;, score=0.752 total time=   0.2s\n",
      "[CV 5/5] END ....................n_neighbors=53;, score=0.748 total time=   0.2s\n",
      "[CV 1/5] END ....................n_neighbors=55;, score=0.748 total time=   0.2s\n",
      "[CV 2/5] END ....................n_neighbors=55;, score=0.754 total time=   0.2s\n",
      "[CV 3/5] END ....................n_neighbors=55;, score=0.756 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=55;, score=0.754 total time=   0.2s\n",
      "[CV 5/5] END ....................n_neighbors=55;, score=0.752 total time=   0.2s\n",
      "[CV 1/5] END ....................n_neighbors=57;, score=0.749 total time=   0.2s\n",
      "[CV 2/5] END ....................n_neighbors=57;, score=0.756 total time=   0.2s\n",
      "[CV 3/5] END ....................n_neighbors=57;, score=0.756 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=57;, score=0.756 total time=   0.2s\n",
      "[CV 5/5] END ....................n_neighbors=57;, score=0.749 total time=   0.2s\n",
      "[CV 1/5] END ....................n_neighbors=59;, score=0.750 total time=   0.3s\n",
      "[CV 2/5] END ....................n_neighbors=59;, score=0.755 total time=   0.2s\n",
      "[CV 3/5] END ....................n_neighbors=59;, score=0.755 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=59;, score=0.754 total time=   0.2s\n",
      "[CV 5/5] END ....................n_neighbors=59;, score=0.748 total time=   0.2s\n",
      "[CV 1/5] END ....................n_neighbors=61;, score=0.753 total time=   0.3s\n",
      "[CV 2/5] END ....................n_neighbors=61;, score=0.754 total time=   0.2s\n",
      "[CV 3/5] END ....................n_neighbors=61;, score=0.754 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=61;, score=0.754 total time=   0.2s\n",
      "[CV 5/5] END ....................n_neighbors=61;, score=0.749 total time=   0.2s\n",
      "[CV 1/5] END ....................n_neighbors=63;, score=0.750 total time=   0.2s\n",
      "[CV 2/5] END ....................n_neighbors=63;, score=0.756 total time=   0.2s\n",
      "[CV 3/5] END ....................n_neighbors=63;, score=0.752 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=63;, score=0.754 total time=   0.2s\n",
      "[CV 5/5] END ....................n_neighbors=63;, score=0.749 total time=   0.2s\n",
      "[CV 1/5] END ....................n_neighbors=65;, score=0.751 total time=   0.2s\n",
      "[CV 2/5] END ....................n_neighbors=65;, score=0.756 total time=   0.2s\n",
      "[CV 3/5] END ....................n_neighbors=65;, score=0.754 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=65;, score=0.755 total time=   0.3s\n",
      "[CV 5/5] END ....................n_neighbors=65;, score=0.748 total time=   0.2s\n",
      "[CV 1/5] END ....................n_neighbors=67;, score=0.751 total time=   0.2s\n",
      "[CV 2/5] END ....................n_neighbors=67;, score=0.755 total time=   0.2s\n",
      "[CV 3/5] END ....................n_neighbors=67;, score=0.750 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=67;, score=0.754 total time=   0.2s\n",
      "[CV 5/5] END ....................n_neighbors=67;, score=0.746 total time=   0.2s\n",
      "[CV 1/5] END ....................n_neighbors=69;, score=0.751 total time=   0.2s\n",
      "[CV 2/5] END ....................n_neighbors=69;, score=0.756 total time=   0.2s\n",
      "[CV 3/5] END ....................n_neighbors=69;, score=0.753 total time=   0.2s\n",
      "[CV 4/5] END ....................n_neighbors=69;, score=0.755 total time=   0.3s\n",
      "[CV 5/5] END ....................n_neighbors=69;, score=0.744 total time=   0.2s\n",
      "[CV 1/5] END ....................n_neighbors=71;, score=0.750 total time=   0.3s\n",
      "[CV 2/5] END ....................n_neighbors=71;, score=0.758 total time=   0.3s\n",
      "[CV 3/5] END ....................n_neighbors=71;, score=0.751 total time=   0.3s\n",
      "[CV 4/5] END ....................n_neighbors=71;, score=0.755 total time=   0.3s\n",
      "[CV 5/5] END ....................n_neighbors=71;, score=0.743 total time=   0.3s\n",
      "[CV 1/5] END ....................n_neighbors=73;, score=0.750 total time=   0.3s\n",
      "[CV 2/5] END ....................n_neighbors=73;, score=0.756 total time=   0.3s\n",
      "[CV 3/5] END ....................n_neighbors=73;, score=0.751 total time=   0.3s\n",
      "[CV 4/5] END ....................n_neighbors=73;, score=0.753 total time=   0.3s\n",
      "[CV 5/5] END ....................n_neighbors=73;, score=0.743 total time=   0.3s\n",
      "[CV 1/5] END ....................n_neighbors=75;, score=0.751 total time=   0.3s\n",
      "[CV 2/5] END ....................n_neighbors=75;, score=0.760 total time=   0.3s\n",
      "[CV 3/5] END ....................n_neighbors=75;, score=0.750 total time=   0.3s\n",
      "[CV 4/5] END ....................n_neighbors=75;, score=0.754 total time=   0.3s\n",
      "[CV 5/5] END ....................n_neighbors=75;, score=0.740 total time=   0.3s\n",
      "[CV 1/5] END ....................n_neighbors=77;, score=0.751 total time=   0.3s\n",
      "[CV 2/5] END ....................n_neighbors=77;, score=0.758 total time=   0.3s\n",
      "[CV 3/5] END ....................n_neighbors=77;, score=0.753 total time=   0.3s\n",
      "[CV 4/5] END ....................n_neighbors=77;, score=0.754 total time=   0.3s\n",
      "[CV 5/5] END ....................n_neighbors=77;, score=0.742 total time=   0.3s\n",
      "[CV 1/5] END ....................n_neighbors=79;, score=0.750 total time=   0.3s\n",
      "[CV 2/5] END ....................n_neighbors=79;, score=0.760 total time=   0.3s\n",
      "[CV 3/5] END ....................n_neighbors=79;, score=0.754 total time=   0.3s\n",
      "[CV 4/5] END ....................n_neighbors=79;, score=0.753 total time=   0.3s\n",
      "[CV 5/5] END ....................n_neighbors=79;, score=0.744 total time=   0.3s\n",
      "[CV 1/5] END ....................n_neighbors=81;, score=0.752 total time=   0.3s\n",
      "[CV 2/5] END ....................n_neighbors=81;, score=0.759 total time=   0.3s\n",
      "[CV 3/5] END ....................n_neighbors=81;, score=0.754 total time=   0.3s\n",
      "[CV 4/5] END ....................n_neighbors=81;, score=0.754 total time=   0.3s\n",
      "[CV 5/5] END ....................n_neighbors=81;, score=0.745 total time=   0.3s\n",
      "[CV 1/5] END ....................n_neighbors=83;, score=0.751 total time=   0.3s\n",
      "[CV 2/5] END ....................n_neighbors=83;, score=0.756 total time=   0.3s\n",
      "[CV 3/5] END ....................n_neighbors=83;, score=0.753 total time=   0.3s\n",
      "[CV 4/5] END ....................n_neighbors=83;, score=0.753 total time=   0.3s\n",
      "[CV 5/5] END ....................n_neighbors=83;, score=0.746 total time=   0.3s\n",
      "[CV 1/5] END ....................n_neighbors=85;, score=0.753 total time=   0.3s\n",
      "[CV 2/5] END ....................n_neighbors=85;, score=0.758 total time=   0.3s\n",
      "[CV 3/5] END ....................n_neighbors=85;, score=0.753 total time=   0.3s\n",
      "[CV 4/5] END ....................n_neighbors=85;, score=0.754 total time=   0.3s\n",
      "[CV 5/5] END ....................n_neighbors=85;, score=0.748 total time=   0.3s\n",
      "[CV 1/5] END ....................n_neighbors=87;, score=0.754 total time=   0.3s\n",
      "[CV 2/5] END ....................n_neighbors=87;, score=0.759 total time=   0.3s\n",
      "[CV 3/5] END ....................n_neighbors=87;, score=0.752 total time=   0.3s\n",
      "[CV 4/5] END ....................n_neighbors=87;, score=0.754 total time=   0.3s\n",
      "[CV 5/5] END ....................n_neighbors=87;, score=0.748 total time=   0.3s\n",
      "[CV 1/5] END ....................n_neighbors=89;, score=0.753 total time=   0.3s\n",
      "[CV 2/5] END ....................n_neighbors=89;, score=0.757 total time=   0.3s\n",
      "[CV 3/5] END ....................n_neighbors=89;, score=0.752 total time=   0.3s\n",
      "[CV 4/5] END ....................n_neighbors=89;, score=0.755 total time=   0.3s\n",
      "[CV 5/5] END ....................n_neighbors=89;, score=0.746 total time=   0.3s\n",
      "[CV 1/5] END ....................n_neighbors=91;, score=0.753 total time=   0.3s\n",
      "[CV 2/5] END ....................n_neighbors=91;, score=0.757 total time=   0.3s\n",
      "[CV 3/5] END ....................n_neighbors=91;, score=0.752 total time=   0.3s\n",
      "[CV 4/5] END ....................n_neighbors=91;, score=0.754 total time=   0.3s\n",
      "[CV 5/5] END ....................n_neighbors=91;, score=0.748 total time=   0.3s\n",
      "[CV 1/5] END ....................n_neighbors=93;, score=0.755 total time=   0.3s\n",
      "[CV 2/5] END ....................n_neighbors=93;, score=0.756 total time=   0.3s\n",
      "[CV 3/5] END ....................n_neighbors=93;, score=0.755 total time=   0.3s\n",
      "[CV 4/5] END ....................n_neighbors=93;, score=0.753 total time=   0.3s\n",
      "[CV 5/5] END ....................n_neighbors=93;, score=0.745 total time=   0.3s\n",
      "[CV 1/5] END ....................n_neighbors=95;, score=0.755 total time=   0.3s\n",
      "[CV 2/5] END ....................n_neighbors=95;, score=0.756 total time=   0.3s\n",
      "[CV 3/5] END ....................n_neighbors=95;, score=0.755 total time=   0.3s\n",
      "[CV 4/5] END ....................n_neighbors=95;, score=0.754 total time=   0.3s\n",
      "[CV 5/5] END ....................n_neighbors=95;, score=0.748 total time=   0.3s\n",
      "[CV 1/5] END ....................n_neighbors=97;, score=0.755 total time=   0.3s\n",
      "[CV 2/5] END ....................n_neighbors=97;, score=0.758 total time=   0.3s\n",
      "[CV 3/5] END ....................n_neighbors=97;, score=0.755 total time=   0.3s\n",
      "[CV 4/5] END ....................n_neighbors=97;, score=0.754 total time=   0.3s\n",
      "[CV 5/5] END ....................n_neighbors=97;, score=0.750 total time=   0.3s\n",
      "[CV 1/5] END ....................n_neighbors=99;, score=0.752 total time=   0.3s\n",
      "[CV 2/5] END ....................n_neighbors=99;, score=0.754 total time=   0.3s\n",
      "[CV 3/5] END ....................n_neighbors=99;, score=0.755 total time=   0.3s\n",
      "[CV 4/5] END ....................n_neighbors=99;, score=0.754 total time=   0.3s\n",
      "[CV 5/5] END ....................n_neighbors=99;, score=0.751 total time=   0.3s\n",
      "[CV 1/5] END ...................n_neighbors=101;, score=0.751 total time=   0.3s\n",
      "[CV 2/5] END ...................n_neighbors=101;, score=0.756 total time=   0.3s\n",
      "[CV 3/5] END ...................n_neighbors=101;, score=0.754 total time=   0.3s\n",
      "[CV 4/5] END ...................n_neighbors=101;, score=0.753 total time=   0.3s\n",
      "[CV 5/5] END ...................n_neighbors=101;, score=0.748 total time=   0.3s\n",
      "[CV 1/5] END ...................n_neighbors=103;, score=0.752 total time=   0.3s\n",
      "[CV 2/5] END ...................n_neighbors=103;, score=0.756 total time=   0.3s\n",
      "[CV 3/5] END ...................n_neighbors=103;, score=0.752 total time=   0.3s\n",
      "[CV 4/5] END ...................n_neighbors=103;, score=0.753 total time=   0.3s\n",
      "[CV 5/5] END ...................n_neighbors=103;, score=0.750 total time=   0.3s\n",
      "Metrics: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.97      0.86      2050\n",
      "           1       0.46      0.07      0.12       655\n",
      "\n",
      "    accuracy                           0.76      2705\n",
      "   macro avg       0.62      0.52      0.49      2705\n",
      "weighted avg       0.69      0.76      0.68      2705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "Range = list(range(1, int(sqrt(len(X_Train))), 2))\n",
    "Param_grid = dict(n_neighbors=Range)    \n",
    "KNN = KNeighborsClassifier()    \n",
    "Grid = GridSearchCV(KNN, Param_grid, cv=5, scoring='accuracy', verbose=3)\n",
    "Grid.fit(X_Train, y_train)\n",
    "best_k = Grid.best_params_['n_neighbors']\n",
    "best_model = Grid.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict(X_Test)\n",
    "print(\"Metrics: \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad5c9a880d58569",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d6f0972b2344568",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T15:22:23.549631Z",
     "start_time": "2024-04-01T15:22:16.970028Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.34      0.50      2050\n",
      "           1       0.31      0.94      0.47       655\n",
      "\n",
      "    accuracy                           0.49      2705\n",
      "   macro avg       0.63      0.64      0.48      2705\n",
      "weighted avg       0.79      0.49      0.49      2705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NB = GaussianNB()\n",
    "Model_Train(NB, X_Train, y_train)\n",
    "\n",
    "y_pred = NB.predict(X_Test)\n",
    "print(\"Metrics: \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08cc4fc3b5bc7f8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## CART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5925c589fa5cdce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T15:30:08.437962Z",
     "start_time": "2024-04-01T15:26:19.079883Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2050\n",
      "           1       1.00      0.99      0.99       655\n",
      "\n",
      "    accuracy                           1.00      2705\n",
      "   macro avg       1.00      0.99      1.00      2705\n",
      "weighted avg       1.00      1.00      1.00      2705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Cart = DecisionTreeClassifier()\n",
    "Model_Train(Cart, X_Train, y_train)\n",
    "\n",
    "y_pred = Cart.predict(X_Test)\n",
    "print(\"Metrics: \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b403d57301d2c426",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aff17b3004eae4fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T15:36:03.437291Z",
     "start_time": "2024-04-01T15:30:54.248013Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      2050\n",
      "           1       1.00      0.89      0.94       655\n",
      "\n",
      "    accuracy                           0.97      2705\n",
      "   macro avg       0.98      0.94      0.96      2705\n",
      "weighted avg       0.97      0.97      0.97      2705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RF = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "Model_Train(RF, X_Train, y_train)\n",
    "\n",
    "y_pred = RF.predict(X_Test)\n",
    "print(\"Metrics: \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cda2d8eccac887b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8681255dc60c8b85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T15:51:47.010235Z",
     "start_time": "2024-04-01T15:42:14.144284Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2050\n",
      "           1       0.99      0.97      0.98       655\n",
      "\n",
      "    accuracy                           0.99      2705\n",
      "   macro avg       0.99      0.98      0.99      2705\n",
      "weighted avg       0.99      0.99      0.99      2705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LogR = LogisticRegression(solver='liblinear', max_iter=2000)\n",
    "Model_Train(LogR, X_Train, y_train)\n",
    "\n",
    "y_pred = LogR.predict(X_Test)\n",
    "print(\"Metrics: \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a5d4f1c2f403f8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5c3d202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      8134\n",
      "           1       0.99      0.98      0.98      2684\n",
      "\n",
      "    accuracy                           0.99     10818\n",
      "   macro avg       0.99      0.99      0.99     10818\n",
      "weighted avg       0.99      0.99      0.99     10818\n",
      "\n",
      "Metrics: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      2050\n",
      "           1       1.00      0.98      0.99       655\n",
      "\n",
      "    accuracy                           0.99      2705\n",
      "   macro avg       0.99      0.99      0.99      2705\n",
      "weighted avg       0.99      0.99      0.99      2705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SVM = LinearSVC(dual=False, max_iter= 10000)\n",
    "Model_Train(SVM, X_Train, y_train)\n",
    "\n",
    "y_pred = SVM.predict(X_Test)\n",
    "print(\"Metrics: \\n\", classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bf8d880f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148b4a5c7acba467",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8febc9f2aca3fe7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T21:55:04.584382Z",
     "start_time": "2024-04-01T21:55:04.430075Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3bedf93e3f526c1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T21:55:07.430531Z",
     "start_time": "2024-04-01T21:55:07.241972Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn = Sequential()\n",
    "nn.add(Dense(128, activation='relu'))\n",
    "nn.add(Dropout(0.2)) \n",
    "nn.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "458d288dbb760bf0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6588 - loss: 69.4746\n",
      "Epoch 2/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7044 - loss: 16.5329\n",
      "Epoch 3/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7158 - loss: 3.3990\n",
      "Epoch 4/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7575 - loss: 1.3627\n",
      "Epoch 5/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7615 - loss: 0.9226\n",
      "Epoch 1/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7619 - loss: 0.7565\n",
      "Epoch 2/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7591 - loss: 0.5067\n",
      "Epoch 3/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7690 - loss: 0.4477\n",
      "Epoch 4/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7726 - loss: 0.4946\n",
      "Epoch 5/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7641 - loss: 0.4944\n",
      "Epoch 1/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7704 - loss: 0.4461\n",
      "Epoch 2/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7802 - loss: 0.4218\n",
      "Epoch 3/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7757 - loss: 0.4286\n",
      "Epoch 4/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7801 - loss: 0.4289\n",
      "Epoch 5/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7786 - loss: 0.4248\n",
      "Epoch 6/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7963 - loss: 0.3883\n",
      "Epoch 7/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7872 - loss: 0.4123\n",
      "Epoch 8/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7788 - loss: 0.4057\n",
      "Epoch 9/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7853 - loss: 0.3913\n",
      "Epoch 10/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7835 - loss: 0.4134\n",
      "Epoch 11/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7752 - loss: 0.4017\n",
      "Epoch 12/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8020 - loss: 0.3594\n",
      "Epoch 13/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7884 - loss: 0.3849\n",
      "Epoch 14/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8061 - loss: 0.3582\n",
      "Epoch 15/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8011 - loss: 0.3769\n",
      "Epoch 16/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8430 - loss: 0.3385\n",
      "Epoch 17/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8315 - loss: 0.3456\n",
      "Epoch 18/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7965 - loss: 0.3594\n",
      "Epoch 19/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8449 - loss: 0.3303\n",
      "Epoch 20/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8419 - loss: 0.3266\n",
      "Epoch 21/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8340 - loss: 0.3363\n",
      "Epoch 22/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8459 - loss: 0.3287\n",
      "Epoch 23/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8599 - loss: 0.3047\n",
      "Epoch 24/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8681 - loss: 0.2944\n",
      "Epoch 25/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8380 - loss: 0.3252\n",
      "Epoch 26/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8902 - loss: 0.2733\n",
      "Epoch 27/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8690 - loss: 0.2949\n",
      "Epoch 28/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8010 - loss: 0.3655\n",
      "Epoch 29/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8516 - loss: 0.3340\n",
      "Epoch 30/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8429 - loss: 0.3180\n",
      "Epoch 31/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8639 - loss: 0.2871\n",
      "Epoch 1/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7802 - loss: 0.3987\n",
      "Epoch 2/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8657 - loss: 0.3077\n",
      "Epoch 3/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8818 - loss: 0.2760\n",
      "Epoch 4/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8569 - loss: 0.3166\n",
      "Epoch 5/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8519 - loss: 0.3124\n",
      "Epoch 6/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8943 - loss: 0.2616\n",
      "Epoch 7/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8520 - loss: 0.3053\n",
      "Epoch 8/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8524 - loss: 0.3008\n",
      "Epoch 9/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8869 - loss: 0.2682\n",
      "Epoch 10/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9023 - loss: 0.2383\n",
      "Epoch 11/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8847 - loss: 0.2579\n",
      "Epoch 12/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8687 - loss: 0.2895\n",
      "Epoch 13/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7826 - loss: 0.3918\n",
      "Epoch 14/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8397 - loss: 0.3287\n",
      "Epoch 15/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8708 - loss: 0.2679\n",
      "Epoch 1/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8843 - loss: 0.3002\n",
      "Epoch 2/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8426 - loss: 0.3209\n",
      "Epoch 3/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8755 - loss: 0.2677\n",
      "Epoch 4/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9342 - loss: 0.2007\n",
      "Epoch 5/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8931 - loss: 0.2627\n",
      "Epoch 6/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9018 - loss: 0.2396\n",
      "Epoch 7/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8438 - loss: 0.3091\n",
      "Epoch 8/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9096 - loss: 0.2173\n",
      "Epoch 9/200\n",
      "\u001b[1m271/271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9021 - loss: 0.2300\n"
     ]
    }
   ],
   "source": [
    "for i,j in KF.split(X_Train):\n",
    "        Train_X = X_Train.iloc[i]\n",
    "        Val_X = X_Train.iloc[j]\n",
    "        Train_Y = y_train.iloc[i]\n",
    "        \n",
    "        nn.fit(Train_X, Train_Y, epochs=200, batch_size=32, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48ea657682a92cfa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T22:29:25.902063Z",
     "start_time": "2024-04-01T22:29:13.457098Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Metrics: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      2050\n",
      "           1       0.88      0.93      0.90       655\n",
      "\n",
      "    accuracy                           0.95      2705\n",
      "   macro avg       0.93      0.94      0.94      2705\n",
      "weighted avg       0.95      0.95      0.95      2705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = nn.predict(X_Test)\n",
    "\n",
    "predictions = []\n",
    "for pred in y_pred:\n",
    "    if pred > 0.5:\n",
    "        predictions.append(1)\n",
    "    else:\n",
    "        predictions.append(0)\n",
    "\n",
    "print(\"Metrics: \\n\", classification_report(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
